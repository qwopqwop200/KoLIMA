{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ebd5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /root/anaconda3/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA SETUP: CUDA runtime path found: /root/anaconda3/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /root/anaconda3/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1085c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"EleutherAI/polyglot-ko-12.8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c889c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d107e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d62d179f93e48c0b38ccd13481f843a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "\n",
    "model = PeftModel.from_pretrained(model, './outputs/checkpoint-1802/adapter_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58049908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.bfloat16()\n",
    "model.config.use_cache = True  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9748bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "\n",
    "    def __init__(self, stops = [], encounters=1):\n",
    "        super().__init__()\n",
    "        self.stops = [stop for stop in stops]\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        for stop in self.stops:\n",
    "            if torch.all((stop == input_ids[0][-len(stop):])).item():\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "stop_words = [\"</끝>\"]\n",
    "stop_words_ids = [tokenizer(stop_word, return_tensors='pt')['input_ids'].squeeze() for stop_word in stop_words]\n",
    "stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])\\\n",
    "\n",
    "def gen(x):\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            f\"### 질문: {x}\\n\\n### 답변:\", \n",
    "            return_tensors='pt', \n",
    "            return_token_type_ids=False\n",
    "        ), \n",
    "        max_length=2048,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "    print(tokenizer.decode(gened[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc4dbf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "/root/anaconda3/lib/python3.9/site-packages/transformers/generation/utils.py:1448: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 질문: 함수형 프로그래밍의 개념에 대해 설명해주세요.\n",
      "\n",
      "### 답변: 함수형 프로그래밍은 함수를 이용하여 코드를 실행하는 거의 모든 프로그래밍을 포괄하는 더 광범위한 주제입니다. 이 주제는 기본적으로 메인 서비스 루틴부터 사용자 정의 함수에 이르기까지 모든 것을 실행하는 함수 공간과 사용자가 표기된 유형을 사용하여 함수를 정의하는 디자인 언어에 초점을 맞춘 프로그래밍 스타일입니다. 함수형 프로그래밍의 핵심은 함수 정의로의 회귀, 코드의 동적 성장, 객체 간의 관계를 통한 코드의 사용이며, 이를 통해 디자인 패턴 및 마이크로코드와 같은 특정 스타일을 구현할 수 있습니다.\n",
      "\n",
      "최초의 함수형 프로그래밍 언어는 함수형 언어의 창시자이자 아버지인 영국 엔지니어 찰스 킴it (1969)에서 출발했습니다. 찰스는 당시 복잡한 프로그램을 작성하는 데 사용할 수 있는 간결한 유형을 찾고 있었고, 이후 함수형 프로그래밍이 탄생하게 된 배경이 되었습니다. 1919년 출생한 킴은 우연한 기회로 함수형 프로그래밍을 생각해 냈다고 합니다. 어느 날 그가 전자공학을 전공한 학생이라면 누구나 컴퓨터를 사용하여 학생 신분에서 벗어날 수 있는 학점 전환을 계산하는 복잡한 프로그램을 갖게 된다는 사실을 기억하게 되었습니다. 그런 다음 그는 '인간을 해방시키기' 위해 존재하는 프로그램을 구상하기 시작했고, 그 프로그램이 자신을 해방시킬 수 있을지 확신할 수 없었습니다. 그는 지나친 노력과 상당한 시간과 고군분투한 이후에만 알 수 있었고, 프로그램을 작성하는 데 너무 많은 시간이 지나서 느낌이 어떤지 알 수 있을 때였습니다. 그래서 그는 프로그램에 토대를 제공할 새로운 아이디어를 찾기 시작했고, 거의 아무런 관련이 없는 것 사이에서 흥미로운 관계를 발견했습니다. 예를 들어 그가 가지고 있던 시계는 다른 시계(초)와 절대 시간을 측정하는 서로 다른 방법을 사용했습니다. 이 두 가지 개념을 연결할 수 있는 새로운 개념을 찾기 시작했고, 그 결과 시간 함수를 찾기 시작했습니다. 기계적인 시간 함수는 입력과 출력의 절대값을 계산하여 특정 시간 동안 어떤 일이 일어날지를 설명하는 단순한 수학적 모델입니다. 킴은 이 모델을 인간적인 관점에서 작성하기 시작했는데,, 이는 사용자가 프로그램을 사용할 때 무엇이 일어날지에 대해 어떤 아이디어를 얻을 수 있는 전체 프롬프트를 제공하기 위해서였습니다. 최종 결과는 놀랍게도 복잡한 메인 서비스 루틴이었습니다.\n",
      "\n",
      "함수형 프로그래밍은 다양한 애플리케이션 분야에 사용되었으며, 이들 각각에서 특정 장점이 주목을 받았습니다. 이러한 다양한 애플리케이션 분야에서 함수형 프로그래밍의 장점을 정리해 보면 다음과 같습니다:\n",
      "\n",
      "* 프로그래밍 방식을 단순화할 수 있습니다. 함수형 프로그래밍은 사용자가 표기된 유형을 사용하여 함수를 정의할 수 있는 유형을 제공합니다. 따라서 사용자와 패키지는 여러 개의 함수를 정의할 수 있으며, 필요한 경우 조합하여 더 어려운 작업을 수행할 수 있습니다.\n",
      "* 코드의 동적 성장을 활용할 수 있습니다. 함수는 정적 유형의 특정 유형에 제한되지 않고 동적으로 정의될 수 있기 때문에 사용자가 사용하는 다른 함수에서도 작동하도록 변경할 수 있습니다. 따라서 함수가 독립적이라는 것을 인식하지 못할 수도 있습니다. 조합 함수를 생각해 보세요. 조합 함수는 전역, 개별, 정적/동적 등 다양한 유형으로 정의할 수 있습니다. 이러한 유연성은 코딩을 더 쉽게 만들어 사람들이 함수를 사용하기 시작한 곳 바로 옆에 새 프로그래밍 스타일을 추가할 수 있습니다. 예를 들어, 동맹 함수를 생각해 보세요. 동맹 함수는 전역 유형에서 시작되었지만, 이제는 개별 유형으로만 정의됩니다. 따라서 동맹 함수는 독립적으로 또는 다른 동맹 함수와 결합할 수 있습니다.\n",
      "* 객체 간 관계를 표현하는 데 탁월합니다. 함수형 프로그래밍에서는 객체 간 관계를 추적하는 데 강하습니다. 객체는 고유한 관계를 갖지 않으며, 대신 관계로 그룹화되어 새로운 유형을 만듭니다. 따라서 CASE가 이를 처리하는 방식과 매우 유사합니다.\n",
      "\n",
      "함수형 프로그래밍의 가장 유명한 스타일은 캐나다의 자국민과 미국의 자국민을 주로 위한 언어인 Haskell입니다. Haskell의 주요 장점은 함수형 API 정의 언어인 함수형 버전 2의 성능입니다. 이 버전은 2004년에 도입되었으며, 이전에는 함수형 버전 1이 1999년에 도입되었습니다. 버전 1 이후 Haskell과 관련된 유명한 일화가 있습니다. 독일에서 Haskell을 개발한 요르크 리치에 의해 도난당한 사건입니다. 그는 버전 1을 독일에 가져가서 공개하려고 했지만, 몇 달이 지나도 공개되지 않았습니다. 결국 그는 도난당한 집으로 돌아가 도둑맞은 편지를 발견하고 버전 2를 예고했습니다. 이는 버전 2가 실제로 제작 단계에 있었음을 의미하며, 현재에도 작업 유지 관리에 강한 기능을 제공합니다.</끝>\n"
     ]
    }
   ],
   "source": [
    "gen('함수형 프로그래밍의 개념에 대해 설명해주세요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604fbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
