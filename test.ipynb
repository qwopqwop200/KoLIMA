{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95ebd5aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===================================BUG REPORT===================================\n",
      "Welcome to bitsandbytes. For bug reports, please run\n",
      "\n",
      "python -m bitsandbytes\n",
      "\n",
      " and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n",
      "================================================================================\n",
      "bin /root/anaconda3/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so\n",
      "CUDA SETUP: CUDA runtime path found: /root/anaconda3/lib/libcudart.so.11.0\n",
      "CUDA SETUP: Highest compute capability among GPUs detected: 8.6\n",
      "CUDA SETUP: Detected CUDA version 117\n",
      "CUDA SETUP: Loading binary /root/anaconda3/lib/python3.9/site-packages/bitsandbytes-0.39.0-py3.9.egg/bitsandbytes/libbitsandbytes_cuda117.so...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from transformers.trainer_utils import PREFIX_CHECKPOINT_DIR\n",
    "import bitsandbytes as bnb\n",
    "from peft import LoraConfig, get_peft_model, PeftModel, prepare_model_for_kbit_training\n",
    "from datasets import load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1085c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"EleutherAI/polyglot-ko-12.8b\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c889c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6d107e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4182361424a34568b2c5b219957380f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/28 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, quantization_config=bnb_config, device_map={\"\":0})\n",
    "\n",
    "model = PeftModel.from_pretrained(model, './outputs/checkpoint-515/adapter_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58049908",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model.bfloat16()\n",
    "model.config.use_cache = True  # silence the warnings. Please re-enable for inference!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9748bd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import StoppingCriteria, StoppingCriteriaList\n",
    "\n",
    "class StoppingCriteriaSub(StoppingCriteria):\n",
    "\n",
    "    def __init__(self, stops = [], encounters=1):\n",
    "        super().__init__()\n",
    "        self.stops = [stop for stop in stops]\n",
    "\n",
    "    def __call__(self, input_ids: torch.LongTensor, scores: torch.FloatTensor):\n",
    "        for stop in self.stops:\n",
    "            if torch.all((stop == input_ids[0][-len(stop):])).item():\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "stop_words = [\"</끝>\"]\n",
    "stop_words_ids = [tokenizer(stop_word, return_tensors='pt')['input_ids'].squeeze() for stop_word in stop_words]\n",
    "stopping_criteria = StoppingCriteriaList([StoppingCriteriaSub(stops=stop_words_ids)])\\\n",
    "\n",
    "def gen(x):\n",
    "    gened = model.generate(\n",
    "        **tokenizer(\n",
    "            f\"### 질문: {x}\\n\\n### 답변:\", \n",
    "            return_tensors='pt', \n",
    "            return_token_type_ids=False\n",
    "        ), \n",
    "        max_length=2048,\n",
    "        early_stopping=True,\n",
    "        do_sample=True,\n",
    "        eos_token_id=2,\n",
    "        stopping_criteria=stopping_criteria\n",
    "    )\n",
    "    print(tokenizer.decode(gened[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc4dbf89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### 질문: 세계 2차대전에 대한 에세이를 작성하세요.\n",
      "\n",
      "### 답변: 제1차 세계대전 발발 이후 영국 정부는 독일과의 모든 통신을 제한했습니다. 독일 정부는 보복을 위해 영국과의 모든 통신을 중단했습니다. 1939년, 히틀러는 \"정부와 4번째 정부 총리\"로부터 자신의 나라를 격리했습니다. 1940년 9월1일, 영국은 독일에 선전포고를 했고 6주 뒤에는 모든 전투에서 패배했습니다.*1891년 이후 일곱 나라가 사용한 무기의 총합이 1918년 세계 2차대전이 끝난 후 남은 무기의 총합에 비해 더 적었습니다.세계 2차 대전은 가장 큰 두 군인의 전투로 인한 사망자보다 전체 군인 사망자의 비율이 더 높은 전쟁입니다. 이 비율은 2:1에서 4:1 사이입니다.\n",
      "이는 수백만 명의 죽음을 불러왔고 수백만 명의 사람들에게 파괴를 가져다주었습니다. 이 모든 피해는 승자와 패자 모두에게 엄청난 손실을 입힐 것이며, 그 결과는 우리 모두에게 장기간 영향을 미칠 것입니다.</끝>\n"
     ]
    }
   ],
   "source": [
    "gen('세계 2차대전에 대한 에세이를 작성하세요.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2604fbf0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
